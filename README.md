# ğŸš¢ Titanic Survival Prediction - Machine Learning

Proyecto de clasificaciÃ³n binaria para predecir la supervivencia de pasajeros del Titanic usando tÃ©cnicas de Machine Learning.

## ğŸ“Š Resultados Principales

- **Mejor Modelo:** XGBoost
- **Accuracy en Test:** 85.4%
- **AUC-ROC:** 0.891
- **F1-Score:** 0.83

## ğŸ¯ Objetivo del Proyecto

Desarrollar un modelo de Machine Learning que pueda predecir si un pasajero del Titanic sobreviviÃ³ o no, basÃ¡ndose en caracterÃ­sticas como edad, sexo, clase, familia, etc.

## ğŸ“‹ Contenido del Repositorio

### ğŸ“ Estructura de Carpetas:
```
eva01_machine_learning/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ titanic_survival_analysis.ipynb
â”œâ”€â”€ data/
â”‚   â””â”€â”€ titanic.csv
â”œâ”€â”€ results/
â”‚   â””â”€â”€ (aquÃ­ van las capturas)
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ informe_final_titanic.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### ğŸ“Š Archivos Principales:
- `notebooks/titanic_survival_analysis.ipynb` - AnÃ¡lisis completo del proyecto
- `data/titanic.csv` - Dataset del Titanic
- `requirements.txt` - Lista de librerÃ­as necesarias

## ğŸš€ Instrucciones de EjecuciÃ³n

### **OpciÃ³n 1: Google Colab (Recomendado)**
1. Abre el archivo `notebooks/titanic_survival_analysis.ipynb` en Google Colab
2. Ejecuta todas las celdas en orden
3. Los datos se cargan automÃ¡ticamente desde URL

### **OpciÃ³n 2: Jupyter Local**
1. Clona este repositorio:
```bash
   git clone https://github.com/DiigJoy/eva01_machine_learning.git
   cd titanic-ml-classification
```


2. Instala las dependencias:
   ```bash
   pip install -r requirements.txt
   ```

3. Ejecuta Jupyter Notebook:
   ```bash
   jupyter notebook
   ```

4. Abre `notebooks/titanic_survival_analysis.ipynb`

5. Ejecuta todas las celdas

## ğŸ”§ TecnologÃ­as Utilizadas

- **Python 3.8+**
- **Pandas** - ManipulaciÃ³n de datos
- **NumPy** - Operaciones numÃ©ricas
- **Scikit-learn** - Machine Learning
- **XGBoost** - Algoritmo de gradient boosting
- **Matplotlib/Seaborn** - VisualizaciÃ³n de datos
- **Jupyter Notebook** - Entorno de desarrollo

## ğŸ“ˆ MetodologÃ­a

### 1. **AnÃ¡lisis Exploratorio de Datos (EDA)**
- ExploraciÃ³n de variables y distribuciones
- AnÃ¡lisis de valores faltantes
- Correlaciones entre variables
- Visualizaciones descriptivas

### 2. **PreparaciÃ³n de Datos**
- Limpieza de datos y manejo de valores faltantes
- Feature engineering (creaciÃ³n de nuevas variables)
- Encoding de variables categÃ³ricas
- DivisiÃ³n en conjuntos de entrenamiento, validaciÃ³n y test

### 3. **Modelado**
- ImplementaciÃ³n de mÃºltiples algoritmos:
  - Logistic Regression (baseline)
  - Random Forest
  - XGBoost (mejor modelo)
- ValidaciÃ³n cruzada
- OptimizaciÃ³n de hiperparÃ¡metros

### 4. **EvaluaciÃ³n**
- MÃ©tricas mÃºltiples: Accuracy, Precision, Recall, F1-Score, AUC-ROC
- Matriz de confusiÃ³n
- AnÃ¡lisis de importancia de features
- InterpretaciÃ³n de resultados

## ğŸ“Š Principales Hallazgos

1. **GÃ©nero:** Las mujeres tuvieron 3x mÃ¡s probabilidad de sobrevivir que los hombres
2. **Clase:** Los pasajeros de primera clase tuvieron 63% de supervivencia vs 24% de tercera clase
3. **Edad:** Los niÃ±os y jÃ³venes tuvieron mayor supervivencia
4. **Familia:** Viajar solo redujo las probabilidades de supervivencia
5. **Variables mÃ¡s importantes:** Sexo, Clase, Edad, Tarifa

## ğŸ‘¨â€ğŸ’» Autores

**Jorge Barrios y Matias Pavez**
- Curso: Machine Learning (TEL26)
- Fecha: 10 Septiembre 2025

## ğŸ“„ Licencia

Este proyecto es para fines educativos.

## ğŸ”— Enlaces Adicionales

- [Dataset Original](https://www.kaggle.com/c/titanic)
- [DocumentaciÃ³n de XGBoost](https://xgboost.readthedocs.io/)
- [Scikit-learn](https://scikit-learn.org/)

---